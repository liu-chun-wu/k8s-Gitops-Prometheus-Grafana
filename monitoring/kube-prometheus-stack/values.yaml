# kube-prometheus-stack values for GitOps demo (revised)

prometheus:
  prometheusSpec:
    serviceMonitorSelectorNilUsesHelmValues: false
    serviceMonitorSelector: {}
    serviceMonitorNamespaceSelector: {}
    retention: 30d
    storageSpec:
      volumeClaimTemplate:
        spec:
          storageClassName: standard
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 10Gi
    resources:
      limits:
        cpu: 2000m
        memory: 8Gi
      requests:
        cpu: 100m
        memory: 512Mi
  
  # 配置 Prometheus 服務為 NodePort
  service:
    type: NodePort
    nodePort: 30090

grafana:
  # 設定固定密碼（僅適用於開發/測試環境）
  adminUser: admin
  adminPassword: admin123
  
  persistence:
    enabled: true
    storageClassName: standard
    size: 10Gi

  resources:
    limits:
      cpu: 300m
      memory: 512Mi
    requests:
      cpu: 100m
      memory: 256Mi

  service:
    type: NodePort
    nodePort: 30301

  # 預設套件儀表板先關閉，改用下方「現代化」儀表板
  defaultDashboardsEnabled: false
  defaultDashboardsTimezone: Asia/Taipei

  # 配置額外的 datasource 以支援 dashboard 的變數需求
  additionalDataSources:
    - name: Prometheus
      uid: prometheus
      type: prometheus
      access: proxy
      isDefault: true
      url: http://kube-prometheus-stack-prometheus:9090/
      jsonData:
        timeInterval: 30s
        httpMethod: POST

  # ⬇️ 重點：用 helm chart 內建機制自動匯入最新版儀表板（非 Angular）
  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
        - name: "kubernetes"
          orgId: 1
          folder: "Kubernetes"
          type: file
          disableDeletion: false
          editable: true
          options:
            # 固定使用官方建議的路徑規則 /var/lib/grafana/dashboards/<provider_name>
            path: /var/lib/grafana/dashboards/kubernetes

  # 這些條目會被轉成 ConfigMap，並由 sidecar 送入上面的 providers 路徑
  # Dashboard 配置說明：使用簡單的字串格式指定 datasource
  # 註：移除 k8s-api-server 因為它產生重複的舊版本
  dashboards:
    kubernetes:
      dashboard-21012:
        gnetId: 21012  # Mixin / Compute Resources / Namespace (Pods)
        revision: 1
        datasource: Prometheus
      dashboard-21016:
        gnetId: 21016  # Mixin / Compute Resources / Namespace (Workloads)
        revision: 1
        datasource: Prometheus
      node-exporter-full:
        gnetId: 1860  # Node Exporter Full - 經典的系統監控 dashboard
        revision: 37
        datasource: Prometheus

  sidecar:
    # 讓 sidecar 幫你自動載入 dashboards / datasources（包含外部 CM）
    dashboards:
      enabled: true
      searchNamespace: ALL
      # 可用 annotation 指定儀表板資料夾
      folderAnnotation: grafana_folder
      provider:
        foldersFromFilesStructure: true
    datasources:
      enabled: true

alertmanager:
  enabled: true
  
  # 配置 AlertManager 服務為 NodePort
  service:
    type: NodePort
    nodePort: 30093
  
  # 完整的 AlertManager 配置，包含 Discord 路由
  config:
    global:
      resolve_timeout: 1m
    
    receivers:
    - name: 'null'
    
    - name: 'discord-critical'
      webhook_configs:
      - url: 'http://alertmanager-discord:9094'
        send_resolved: true
        
    - name: 'discord-warning'
      webhook_configs:
      - url: 'http://alertmanager-discord:9094'
        send_resolved: true
        
    - name: 'discord-info'
      webhook_configs:
      - url: 'http://alertmanager-discord:9094'
        send_resolved: true
    
    route:
      group_by: ['alertname', 'cluster', 'service']
      group_wait: 5s
      group_interval: 15s
      repeat_interval: 1m
      receiver: 'null'
      
      routes:
      - match:
          alertname: Watchdog
        receiver: 'null'
        
      - match:
          severity: critical
        receiver: 'discord-critical'
        group_wait: 5s
        repeat_interval: 1m
        
      - match:
          severity: warning
        receiver: 'discord-warning'
        group_wait: 5s
        repeat_interval: 1m
        
      - match:
          severity: info
        receiver: 'discord-info'
        group_wait: 5s
        repeat_interval: 1m
        
      - match_re:
          service: podinfo.*
        receiver: 'discord-warning'
        group_by: ['alertname', 'pod']
        group_wait: 5s
        repeat_interval: 1m
    
    inhibit_rules:
    - source_match:
        severity: 'critical'
      target_match_re:
        severity: 'warning|info'
      equal: ['alertname', 'namespace']
      
    - source_match:
        severity: 'warning'
      target_match:
        severity: 'info'
      equal: ['alertname', 'namespace']
  
  alertmanagerSpec:
    storage:
      volumeClaimTemplate:
        spec:
          storageClassName: standard
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 2Gi
    resources:
      limits:
        cpu: 100m
        memory: 128Mi
      requests:
        cpu: 25m
        memory: 64Mi

nodeExporter:
  enabled: true

kubeStateMetrics:
  enabled: true

kubeEtcd:
  enabled: false
kubeControllerManager:
  enabled: false
kubeScheduler:
  enabled: false
kubeProxy:
  enabled: false

additionalServiceMonitors:
  - name: podinfo-monitor
    selector:
      matchLabels:
        app: podinfo
    namespaceSelector:
      any: true
    endpoints:
      - port: http-metrics
        interval: 15s
        path: /metrics
